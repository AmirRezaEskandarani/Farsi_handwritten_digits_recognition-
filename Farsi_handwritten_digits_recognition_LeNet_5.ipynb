{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Recognize Farsi digits from 0 to 9"
      ],
      "metadata": {
        "id": "_WZyhXv7do8p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfXcbqpLHQCL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mount google drive to load data from my drive"
      ],
      "metadata": {
        "id": "ocskZQqhdxj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CUu6jlfCIdx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to load dataset"
      ],
      "metadata": {
        "id": "YZX_XEg7d7LU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# *-* coding: utf-8 *-*\n",
        "\n",
        "# Hoda Dataset Reader\n",
        "# Python code for reading Hoda farsi digit dataset.\n",
        "\n",
        "# Hoda Farsi Digit Dataset:\n",
        "# http://farsiocr.ir/\n",
        "# http://farsiocr.ir/مجموعه-داده/مجموعه-ارقام-دستنویس-هدی\n",
        "# http://dadegan.ir/catalog/hoda\n",
        "\n",
        "# Repository:\n",
        "# https://github.com/amir-saniyan/HodaDatasetReader\n",
        "\n",
        "import struct\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\n",
        "def __convert_to_one_hot(vector, num_classes):\n",
        "    result = np.zeros(shape=[len(vector), num_classes])\n",
        "    result[np.arange(len(vector)), vector] = 1\n",
        "    return result\n",
        "\n",
        "\n",
        "def __resize_image(src_image, dst_image_height, dst_image_width):\n",
        "    src_image_height = src_image.shape[0]\n",
        "    src_image_width = src_image.shape[1]\n",
        "\n",
        "    if src_image_height > dst_image_height or src_image_width > dst_image_width:\n",
        "        height_scale = dst_image_height / src_image_height\n",
        "        width_scale = dst_image_width / src_image_width\n",
        "        scale = min(height_scale, width_scale)\n",
        "        img = cv2.resize(src=src_image, dsize=(0, 0), fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
        "    else:\n",
        "        img = src_image\n",
        "\n",
        "    img_height = img.shape[0]\n",
        "    img_width = img.shape[1]\n",
        "\n",
        "    dst_image = np.zeros(shape=[dst_image_height, dst_image_width], dtype=np.uint8)\n",
        "\n",
        "    y_offset = (dst_image_height - img_height) // 2\n",
        "    x_offset = (dst_image_width - img_width) // 2\n",
        "\n",
        "    dst_image[y_offset:y_offset+img_height, x_offset:x_offset+img_width] = img\n",
        "\n",
        "    return dst_image\n",
        "\n",
        "\n",
        "def read_hoda_cdb(file_name):\n",
        "    with open(file_name, 'rb') as binary_file:\n",
        "\n",
        "        data = binary_file.read()\n",
        "\n",
        "        offset = 0\n",
        "\n",
        "        # read private header\n",
        "\n",
        "        yy = struct.unpack_from('H', data, offset)[0]\n",
        "        offset += 2\n",
        "\n",
        "        m = struct.unpack_from('B', data, offset)[0]\n",
        "        offset += 1\n",
        "\n",
        "        d = struct.unpack_from('B', data, offset)[0]\n",
        "        offset += 1\n",
        "\n",
        "        H = struct.unpack_from('B', data, offset)[0]\n",
        "        offset += 1\n",
        "\n",
        "        W = struct.unpack_from('B', data, offset)[0]\n",
        "        offset += 1\n",
        "\n",
        "        TotalRec = struct.unpack_from('I', data, offset)[0]\n",
        "        offset += 4\n",
        "\n",
        "        LetterCount = struct.unpack_from('128I', data, offset)\n",
        "        offset += 128 * 4\n",
        "\n",
        "        imgType = struct.unpack_from('B', data, offset)[0]  # 0: binary, 1: gray\n",
        "        offset += 1\n",
        "\n",
        "        Comments = struct.unpack_from('256c', data, offset)\n",
        "        offset += 256 * 1\n",
        "\n",
        "        Reserved = struct.unpack_from('245c', data, offset)\n",
        "        offset += 245 * 1\n",
        "\n",
        "        if (W > 0) and (H > 0):\n",
        "            normal = True\n",
        "        else:\n",
        "            normal = False\n",
        "\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for i in range(TotalRec):\n",
        "\n",
        "            StartByte = struct.unpack_from('B', data, offset)[0]  # must be 0xff\n",
        "            offset += 1\n",
        "\n",
        "            label = struct.unpack_from('B', data, offset)[0]\n",
        "            offset += 1\n",
        "\n",
        "            if not normal:\n",
        "                W = struct.unpack_from('B', data, offset)[0]\n",
        "                offset += 1\n",
        "\n",
        "                H = struct.unpack_from('B', data, offset)[0]\n",
        "                offset += 1\n",
        "\n",
        "            ByteCount = struct.unpack_from('H', data, offset)[0]\n",
        "            offset += 2\n",
        "\n",
        "            image = np.zeros(shape=[H, W], dtype=np.uint8)\n",
        "\n",
        "            if imgType == 0:\n",
        "                # Binary\n",
        "                for y in range(H):\n",
        "                    bWhite = True\n",
        "                    counter = 0\n",
        "                    while counter < W:\n",
        "                        WBcount = struct.unpack_from('B', data, offset)[0]\n",
        "                        offset += 1\n",
        "                        # x = 0\n",
        "                        # while x < WBcount:\n",
        "                        #     if bWhite:\n",
        "                        #         image[y, x + counter] = 0  # Background\n",
        "                        #     else:\n",
        "                        #         image[y, x + counter] = 255  # ForeGround\n",
        "                        #     x += 1\n",
        "                        if bWhite:\n",
        "                            image[y, counter:counter + WBcount] = 0  # Background\n",
        "                        else:\n",
        "                            image[y, counter:counter + WBcount] = 255  # ForeGround\n",
        "                        bWhite = not bWhite  # black white black white ...\n",
        "                        counter += WBcount\n",
        "            else:\n",
        "                # GrayScale mode\n",
        "                data = struct.unpack_from('{}B'.format(W * H), data, offset)\n",
        "                offset += W * H\n",
        "                image = np.asarray(data, dtype=np.uint8).reshape([W, H]).T\n",
        "\n",
        "            images.append(image)\n",
        "            labels.append(label)\n",
        "\n",
        "        return images, labels\n",
        "\n",
        "\n",
        "def read_hoda_dataset(dataset_path, images_height=32, images_width=32, one_hot=False, reshape=True):\n",
        "    images, labels = read_hoda_cdb(dataset_path)\n",
        "    assert len(images) == len(labels)\n",
        "\n",
        "    X = np.zeros(shape=[len(images), images_height, images_width], dtype=np.float32)\n",
        "    Y = np.zeros(shape=[len(labels)], dtype=np.int)\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        image = images[i]\n",
        "        # Image resizing.\n",
        "        image = __resize_image(src_image=image, dst_image_height=images_height, dst_image_width=images_width)\n",
        "        # Image normalization.\n",
        "        image = image / 255.0\n",
        "        # Image binarization.\n",
        "        image = np.where(image >= 0.5, 1, 0)\n",
        "        # Image.\n",
        "        X[i] = image\n",
        "        # Label.\n",
        "        Y[i] = labels[i]\n",
        "\n",
        "    if one_hot:\n",
        "        Y = __convert_to_one_hot(Y, 10).astype(dtype=np.float32)\n",
        "    else:\n",
        "        Y = Y.astype(dtype=np.float32)\n",
        "\n",
        "    if reshape:\n",
        "        X = X.reshape(-1, images_height * images_width)\n",
        "    else:\n",
        "        X = X.reshape(-1, images_height, images_width, 1)\n",
        "\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "tOtpMmYDBISQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load train data"
      ],
      "metadata": {
        "id": "aREErrh_eHAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = read_hoda_dataset('/content/drive/MyDrive/Data mining/Farsi digits/Train 60000.cdb')"
      ],
      "metadata": {
        "id": "pn0XShgRDSgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load test data"
      ],
      "metadata": {
        "id": "qtfETLlYeJKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y_test = read_hoda_dataset('/content/drive/MyDrive/Data mining/Farsi digits/Test 20000.cdb')\n"
      ],
      "metadata": {
        "id": "IefpBXSGHoja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### take validation data from train data"
      ],
      "metadata": {
        "id": "dg9FvToieLSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = X_train[50000:]\n",
        "y_val = y_train[50000:]\n",
        "X_train = X_train[:50000]\n",
        "y_train = y_train[:50000]"
      ],
      "metadata": {
        "id": "Y2O6wT9aGami"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val.shape"
      ],
      "metadata": {
        "id": "oU1SqLtvHd-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image(position):\n",
        "  image = train['features'][position].squeeze()\n",
        "  plt.title(f'Example {position}. Label: {train[\"labels\"][position]}')\n",
        "  plt.imshow(image, cmap=plt.cm.gray_r)"
      ],
      "metadata": {
        "id": "3kGWLo9264n3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reshape to be [samples][width][height][channels]"
      ],
      "metadata": {
        "id": "LnSx_A1KeQid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], 32, 32, 1)).astype('float32')\n",
        "X_test = X_test.reshape((X_test.shape[0], 32, 32, 1)).astype('float32')\n",
        "X_val = X_val.reshape((X_val.shape[0], 32, 32, 1)).astype('float32')"
      ],
      "metadata": {
        "id": "Bzvc5ORLAfB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "uF1OlD_9Eq2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "IDvF4Gk1Yhwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val.shape"
      ],
      "metadata": {
        "id": "wW8PNkqgYlID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  one hot encode outputs and get number fo classes"
      ],
      "metadata": {
        "id": "i__JrEZZefyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "y_val = to_categorical(y_val)\n",
        "# num_classes = y_test.shape[1]"
      ],
      "metadata": {
        "id": "FbQ63oD2Ka7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### define and compile the model"
      ],
      "metadata": {
        "id": "Kx-tiYD1ekN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_model_LeNet_5():\n",
        "\n",
        "  lenet_5_model = Sequential()\n",
        "  lenet_5_model.add(Conv2D(6, kernel_size=5, strides=1,  activation='tanh', input_shape=(32, 32, 1), padding='same')) #C1\n",
        "  lenet_5_model.add(AveragePooling2D()) #S2\n",
        "  lenet_5_model.add(Conv2D(16, kernel_size=5, strides=1, activation='tanh', padding='valid')) #C3\n",
        "  lenet_5_model.add(AveragePooling2D()) #S4\n",
        "  lenet_5_model.add(Conv2D(120, kernel_size=5, strides=1, activation='tanh', padding='valid')) #C5\n",
        "  lenet_5_model.add(Flatten()) #Flatten    \n",
        "  lenet_5_model.add(Dense(84, activation='tanh')) #F6\n",
        "  lenet_5_model.add(Dense(10, activation='softmax')) #Output layer\n",
        "  lenet_5_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return lenet_5_model\n",
        "\n",
        "model = cnn_model_LeNet_5()"
      ],
      "metadata": {
        "id": "G3VQopvn3BsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "g1kHIf2CE3I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, 'model.jpg', show_shapes=True)"
      ],
      "metadata": {
        "id": "4aaMHitHZOcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit the model\n"
      ],
      "metadata": {
        "id": "cjbMxBLEepIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_val.shape"
      ],
      "metadata": {
        "id": "i20zL8O15MeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### use early stop to avoid overfitting"
      ],
      "metadata": {
        "id": "GVecJrlTnF48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('./model/model.h5', save_best_only=True)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=128, callbacks=[checkpoint_cb, early_stopping_cb])\n",
        "model = keras.models.load_model('./model/model.h5')\n"
      ],
      "metadata": {
        "id": "vBPAoRI0LAb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### calculate loss and accuray of the model"
      ],
      "metadata": {
        "id": "Lp70ZrqsesSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'loss for the model is {loss} \\naccuracy for the model is {accuracy}')"
      ],
      "metadata": {
        "id": "FNa9NqUGLEQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### plot training and validation accuracy"
      ],
      "metadata": {
        "id": "DqWkMOYZrODN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(20)\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WEbWVMYJnu6q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}